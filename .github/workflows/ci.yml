# ============================================
# üöÄ GitHub Actions CI/CD Pipeline
# ============================================
# Runs tests, backtests, and validates strategy

name: Trading Bot CI

on:
  push:
    branches: [main, develop]
    tags: ['v*', 'release-*']
  schedule:
    - cron: '0 4 * * 0'  # Weekly on Sundays at 04:00 UTC
  pull_request:
    branches: [main]
  workflow_dispatch:
    inputs:
      run_extended_backtest:
        description: 'Run extended backtest (longer)'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.12'
  COVERAGE_THRESHOLD: '0.60'
  COVERAGE_STRICT: 'false'
  VALIDATION_FAIL_ON_UNDERPERFORM: 'false'
  MIN_ALPHA_TO_FAIL: '-0.005'
  RUN_EXTENDED_BACKTEST: 'false'
  VALIDATION_FAIL_ON_UNDERPERFORM: 'false'

jobs:
  # ----------------------------------------
  # üß™ Unit Tests
  # ----------------------------------------
  test:
    name: Unit Tests
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirement.txt
          pip install pre-commit black ruff==0.14.8
          pip install pytest pytest-cov

      - name: üß™ Run tests
        run: |
          python -m pytest tests/ -v --cov=src --cov-report=xml

      - name: ‚öôÔ∏è Run pre-commit hooks
        run: |
          pre-commit run --all-files || true

      - name: üìä Upload coverage (optional)
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}
        run: |
          if [ -z "$CODECOV_TOKEN" ]; then
            echo "No CODECOV_TOKEN set - skipping upload to Codecov"
          else
            echo "Uploading coverage to Codecov..."
            # Use codecov-action bash uploader as a fallback (action requires token)
            curl -s https://codecov.io/bash | bash -s -- -f coverage.xml -t "$CODECOV_TOKEN" || true
          fi

      - name: üî¢ Check coverage threshold
        run: |
          python - <<'PY'
          import xml.etree.ElementTree as ET
          import sys
          import os
          try:
            tree = ET.parse('coverage.xml')
            root = tree.getroot()
            rate = float(root.get('line-rate', '0'))
            print(f'Coverage line-rate: {rate:.3f}')
            threshold = float(os.environ.get('COVERAGE_THRESHOLD', '0.60'))
            if rate < threshold:
              print(
                f'‚ùå Coverage below threshold of {threshold*100:.0f}%: {rate*100:.2f}%'
              )
              strict = os.environ.get('COVERAGE_STRICT', 'false').lower() in (
                '1', 'true', 'yes'
              )
              if strict:
                sys.exit(1)
              else:
                print(
                  '‚ö†Ô∏è Coverage below threshold but COVERAGE_STRICT is not set; continuing'
                )
            else:
              print(
                f'‚úÖ Coverage OK: {rate*100:.2f}% >= {threshold*100:.0f}%'
              )
          except FileNotFoundError:
            print('‚ö†Ô∏è coverage.xml not found, skipping coverage threshold check')
          PY

  # ----------------------------------------
  # üìà Backtest Validation
  # ----------------------------------------
  backtest:
    name: Backtest Strategy
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirement.txt

      - name: üèÉ Generate CI dataset and Run backtest (CLI)
        run: |
          mkdir -p outputs data
          cat > data/ci_data.csv <<'CSV'
          epoch,Asset A,Asset B,Cash
          0,111329.99,4299.38,1.0
          1,111259.99,4293.48,1.0
          2,111137.34,4306.19,1.0
          3,111052.11,4311.87,1.0
          4,111280.39,4291.78,1.0
          5,112052.43,4312.41,1.0
          6,112631.75,4371.64,1.0
          7,112097.31,4293.00,1.0
          8,112065.23,4306.37,1.0
          CSV
          python tradebot.py backtest --data data/ci_data.csv --strategy safe_profit --output outputs/ci_backtest

      - name: üìä Calculate scores (via src engine)
        id: score
        run: |
          python - <<'PY'
          import sys
          import os
          sys.path.insert(0, '.')
          from src.data.sources import DataSourceFactory
          from src.strategies import StrategyFactory
          from src.engine.backtest import BacktestConfig, BacktestEngine, StrategyComparator

            strat = StrategyFactory.create('safe_profit')
            cfg = BacktestConfig(initial_capital=10000)
            engine = BacktestEngine(cfg)
            comp = StrategyComparator(cfg)

            # Determine datasets to run
            run_extended = os.environ.get('RUN_EXTENDED_BACKTEST', 'false').lower() in ('1','true','yes')
            datasets = ['data/ci_data.csv']
            if run_extended:
              extended_files = [
                'data/crypto_btc_eth_4h_90d.csv',
                'data/crypto_btc_eth_1h_60d.csv',
                'data/crypto_btc_eth_1h_30d.csv',
              ]
              # Use files that exist; otherwise generate synthetic variations
              datasets = [f for f in extended_files if os.path.exists(f)]
              if not datasets:
                # Create a few synthetic variants based on ci_data.csv
                import csv
                base = []
                with open('data/ci_data.csv', 'r') as fh:
                  reader = csv.DictReader(fh)
                  for row in reader:
                    base.append(row)
                for i, factor in enumerate([1.0, 0.98, 1.02], start=1):
                  out_path = f'data/ci_data_var{i}.csv'
                  with open(out_path, 'w') as out:
                    out.write('epoch,Asset A,Asset B,Cash\n')
                    for r in base:
                      epoch = r['epoch']
                      a = float(r['Asset A']) * factor
                      b = float(r['Asset B']) * (1.0 + (factor - 1.0) * 0.5)
                      out.write(f"{epoch},{a:.2f},{b:.2f},{r['Cash']}\n")
                  datasets.append(out_path)
          print('='*50)
          print('üìä BACKTEST RESULTS')
          print('='*50)
            alphas = []
            results = []
            for ds_file in datasets:
              ds = DataSourceFactory.from_csv(ds_file)
              res = engine.run(strat, ds)
              bm = comp.calculate_benchmark(ds)
              base = res.total_return
              sharpe = res.sharpe_ratio
              pnl = res.pnl if hasattr(res, 'pnl') else 0
              alpha = base - bm['50_50']
              alphas.append(alpha)
              results.append((ds_file, base, sharpe, res.max_drawdown, pnl, alpha))
              print('\nDataset:', ds_file)
              print('Return:', base)
              print('Sharpe:', sharpe)
              print('Max DD:', res.max_drawdown)
              print('Alpha vs 50/50:', alpha)
          # Write outputs for summary
          print('\n')
          with open('$GITHUB_OUTPUT', 'a') as f:
            f.write(f'base_score={base:.4f}\n')
            f.write(f'sharpe_score={sharpe:.4f}\n')
            f.write(f'pnl_score={pnl:.4f}\n')
          # Also write CSV metrics for artifact upload
          import os
          os.makedirs('outputs', exist_ok=True)
          with open('outputs/ci_backtest.csv', 'w') as csvfile:
            csvfile.write('dataset,base_return,sharpe,max_drawdown,pnl,alpha\n')
            for dsf, base, sharpe, max_dd, pnl, alpha in results:
              csvfile.write(f'{dsf},{base:.6f},{sharpe:.6f},{max_dd:.6f},{pnl:.6f},{alpha:.6f}\n')
            # aggregate
            avg_alpha = sum(alphas) / len(alphas) if alphas else 0.0
            csvfile.write(f'avg_alpha,{avg_alpha:.6f}\n')
          # Fail if underperform vs 50/50 (controlled by VALIDATION_FAIL_ON_UNDERPERFORM)
          fail_on_underperform = os.environ.get('VALIDATION_FAIL_ON_UNDERPERFORM', 'false').lower() in ('1', 'true', 'yes')
          min_alpha = float(os.environ.get('MIN_ALPHA_TO_FAIL', '-0.005'))
          avg_alpha = sum(alphas) / len(alphas) if alphas else 0.0
          print('\nAGGREGATE: avg_alpha =', avg_alpha)
          if avg_alpha < min_alpha:
            print('‚ùå Average alpha below threshold')
            if fail_on_underperform:
              print('FAILING because VALIDATION_FAIL_ON_UNDERPERFORM is set')
              sys.exit(1)
            else:
              print('Warning: average alpha below threshold but VALIDATION_FAIL_ON_UNDERPERFORM is false; continuing')
          else:
            print('‚úÖ Strategy passes validation!')
          PY

      - name: üìù Job Summary
        run: |
          echo "## üìä Backtest Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Metric | Score |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Base Score | ${{ steps.score.outputs.base_score }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Sharpe Score | ${{ steps.score.outputs.sharpe_score }} |" >> $GITHUB_STEP_SUMMARY
          echo "| PnL Score | ${{ steps.score.outputs.pnl_score }} |" >> $GITHUB_STEP_SUMMARY

      - name: üì§ Upload results
        uses: actions/upload-artifact@v4
        with:
          name: backtest-results
          path: outputs/ci_backtest/**
          retention-days: 30

  # ----------------------------------------
  # üîÅ Scheduled Backtest (Nightly)
  # ----------------------------------------
  scheduled-backtest:
    name: Nightly Backtest
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirement.txt

      - name: üèÉ Run quick backtest
        run: |
          mkdir -p outputs data
          cat > data/ci_data.csv <<'CSV'
          epoch,Asset A,Asset B,Cash
          0,111329.99,4299.38,1.0
          1,111259.99,4293.48,1.0
          2,111137.34,4306.19,1.0
          3,111052.11,4311.87,1.0
          4,111280.39,4291.78,1.0
          CSV
          python tradebot.py backtest --data data/ci_data.csv --strategy safe_profit --output outputs/nightly_backtest

      - name: üì§ Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: nightly-backtest-results
          path: outputs/nightly_backtest/
          retention-days: 14

  # ----------------------------------------
  # üê≥ Docker Build
  # ----------------------------------------
  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    needs: test

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üèóÔ∏è Build Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          target: production
          push: false
          load: true
          tags: trading-bot:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: üß™ Sanity run (CI) - non-root
        run: |
          docker run --rm trading-bot:latest --help

  # ----------------------------------------
  # üì° Integration / smoke tests using the built image
  # ----------------------------------------
  integration:
    name: Integration Smoke Tests
    runs-on: ubuntu-latest
    needs: docker

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üê≥ Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: üèóÔ∏è Build Docker image for integration
        uses: docker/build-push-action@v6
        with:
          context: .
          target: production
          push: false
          load: true
          tags: trading-bot:latest

      - name: üê≥ Run short backtest in Docker
        run: |
          mkdir -p outputs data
          cat > data/ci_data.csv <<'CSV'
          epoch,Asset A,Asset B,Cash
          0,111329.99,4299.38,1.0
          1,111259.99,4293.48,1.0
          2,111137.34,4306.19,1.0
          3,111052.11,4311.87,1.0
          4,111280.39,4291.78,1.0
          5,112052.43,4312.41,1.0
          6,112631.75,4371.64,1.0
          7,112097.31,4293.00,1.0
          8,112065.23,4306.37,1.0
          CSV
          docker run --rm -v ${GITHUB_WORKSPACE}/data:/app/data trading-bot:latest backtest --data data/ci_data.csv --strategy safe_profit --output /app/outputs/ci_integration_backtest

  # ----------------------------------------
  # Publish to GHCR (manual dispatch only)
  # ----------------------------------------
  publish:
    name: Publish Image
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || startsWith(github.ref, 'refs/tags/')
    needs: docker

    steps:
      - name: üì• Checkout
        uses: actions/checkout@v4

      - name: üîê Login to GHCR
        uses: docker/login-action@v2
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: üèóÔ∏è Build and Push Image to GHCR
        uses: docker/build-push-action@v6
        with:
          context: .
          target: production
          platforms: linux/amd64,linux/arm64
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:latest
            ghcr.io/${{ github.repository }}:${{ github.sha }}

      - name: "üß™ Test Docker image: invoke `test` subcommand to verify imports"
        run: |
          docker run --rm trading-bot:latest test

  # ----------------------------------------
  # üîç Code Quality
  # ----------------------------------------
  lint:
    name: Code Quality
    runs-on: ubuntu-latest

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install linters
        run: |
          pip install ruff

      - name: üîç Run Ruff
        run: |
          pip install ruff==0.14.8
          ruff check src tests --ignore E501,E402
        continue-on-error: true  # Don't fail CI on style issues

  # ----------------------------------------
  # üì° Live API Check (optional)
  # ----------------------------------------
  api-check:
    name: API Connectivity
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch'

    steps:
      - name: üì• Checkout code
        uses: actions/checkout@v4

      - name: üêç Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: üì¶ Install requests
        run: pip install requests

      - name: üì° Check Binance API
        run: |
          python -c "
          import requests
          r = requests.get('https://api.binance.com/api/v3/ticker/price?symbol=BTCUSDT', timeout=10)
          r.raise_for_status()
          price = float(r.json()['price'])
          print(f'‚úÖ Binance API OK - BTC: \${price:,.2f}')
          "

      - name: üì° Check Kraken API
        run: |
          python -c "
          import requests
          r = requests.get('https://api.kraken.com/0/public/Ticker?pair=XBTUSD', timeout=10)
          r.raise_for_status()
          data = r.json()
          price = float(data['result']['XXBTZUSD']['c'][0])
          print(f'‚úÖ Kraken API OK - BTC: \${price:,.2f}')
          "
